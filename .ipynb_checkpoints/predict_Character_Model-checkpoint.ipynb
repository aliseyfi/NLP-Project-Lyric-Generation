{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21247,
     "status": "ok",
     "timestamp": 1586060940211,
     "user": {
      "displayName": "Jesse Borg",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhJTIY1G60GY_OjYcCPZt5JdJCM6kkXTGAgRobe=s64",
      "userId": "14131079589536879976"
     },
     "user_tz": 240
    },
    "id": "hlntePnrksed",
    "outputId": "978aa160-c7e5-4e89-9e23-46bd9abe5aa2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXCU53dUkdmU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load Packages\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "#from __future__ import print_function\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.models import load_model, save_model\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4O9E32UmkwNt"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/My Drive/Colab Notebooks/NLP Group Project/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-2y6o1JkmSp"
   },
   "outputs": [],
   "source": [
    "# Read Songs\n",
    "songs = pd.read_csv('drake-songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1586061286506,
     "user": {
      "displayName": "Jesse Borg",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhJTIY1G60GY_OjYcCPZt5JdJCM6kkXTGAgRobe=s64",
      "userId": "14131079589536879976"
     },
     "user_tz": 240
    },
    "id": "ns3F69xMlCZF",
    "outputId": "6b46a81d-2c15-4dc5-dddb-3c1748c2d05e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367372"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ''\n",
    "\n",
    "for index, row in songs['lyrics'].iteritems():\n",
    "    cleaned = str(row).lower().replace(' ', '\\n')\n",
    "    text = text + \" \".join(re.findall(r\"[a-z']+\", cleaned))\n",
    "    \n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1586061287975,
     "user": {
      "displayName": "Jesse Borg",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhJTIY1G60GY_OjYcCPZt5JdJCM6kkXTGAgRobe=s64",
      "userId": "14131079589536879976"
     },
     "user_tz": 240
    },
    "id": "x6tibuXslDAl",
    "outputId": "18eebd3e-d575-4446-df9b-7a9ea780f39c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 28\n"
     ]
    }
   ],
   "source": [
    "tokens = re.findall(r\"[a-z'\\s]\", text)\n",
    "\n",
    "chars = sorted(list(set(tokens)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 122444\n"
     ]
    }
   ],
   "source": [
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OgKMP2MAlJIh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('drake_character_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, seed, length, diversity):\n",
    "\n",
    "    maxlen = 40\n",
    "    generated = ''\n",
    "    sentence = text[seed: seed + maxlen]\n",
    "    generated += sentence\n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(length):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "    \n",
    "    print('----- Actual Text -----')\n",
    "    print(text[seed:seed+maxlen+length])\n",
    "    \n",
    "    # JG - Added to return generated and actual text for comparison\n",
    "    return generated, text[seed:seed+maxlen+length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 61673,
     "status": "ok",
     "timestamp": 1586062979703,
     "user": {
      "displayName": "Jesse Borg",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhJTIY1G60GY_OjYcCPZt5JdJCM6kkXTGAgRobe=s64",
      "userId": "14131079589536879976"
     },
     "user_tz": 240
    },
    "id": "tSaFhYIwlQUL",
    "outputId": "a99960b9-5c87-4822-9f83-598b6d93c675",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"hoes i suppose i just wanna be i just wa\"\n",
      "hoes i suppose i just wanna be i just want you i'm balling on your house the bent i'm do to in it yeah yeah they don't know you mater in your wavers on the drinking that i own it oh yeah yeah yeah i get it i get it i don't get it i'm goin' \n",
      "----- Actual Text -----\n",
      "hoes i suppose i just wanna be i just wanna be successful i just wanna be i just wanna be successful i just wanna be i just wanna be successful drizzy ah yeah trey i fuckin' feel you they be starin' at the money like it's unfamiliar i get i\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "generate_text(model, 123, 200, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation - Edit Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages for Evaluation\n",
    "from nltk.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store results\n",
    "eval_dict = {}\n",
    "\n",
    "# Loop through different diversity parameters to find the best one\n",
    "for diversity in [0.2, 0.4, 0.6, 0.8]:\n",
    "\n",
    "    total_distance = 0\n",
    "    lines_generated = 0\n",
    "\n",
    "    # Loop through seed values starting at 1 and stepping 10000 (creates 37 rounds per diversity)\n",
    "    for seed in range(1, len(text) - maxlen, 1000):\n",
    "\n",
    "        # Get generated and actual text from model\n",
    "        generated_text, actual_text = generate_text(model, seed, 200, diversity)\n",
    "\n",
    "        # Use edit distance to see difference in characters generated\n",
    "        total_distance += edit_distance(generated_text[maxlen:200+maxlen], actual_text[maxlen:200+maxlen])\n",
    "\n",
    "        lines_generated += 1\n",
    "\n",
    "        # Get average distance\n",
    "        avg_dist = total_distance/lines_generated\n",
    "\n",
    "    # Append results for each level of diversity to dictionary\n",
    "    eval_dict[diversity] = avg_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at results for different diversity levels\n",
    "eval_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Evaluation - Artist Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all generated words\n",
    "generated_sentences = []\n",
    "\n",
    "# Loop through seed values starting at 1 and stepping 10000 (creates 37 rounds per diversity)\n",
    "for seed in range(1, len(text) - maxlen, 1000):\n",
    "  \n",
    "    # Get generated and actual text from model - specify diversity\n",
    "    generated_text, actual_text = generate_text(model, seed, 200, 0.2)\n",
    "\n",
    "    # Just add the characters generated by the model\n",
    "    generated_sentences.append(generated_text[maxlen:maxlen+200])\n",
    "\n",
    "generated_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list to hold all generated words\n",
    "generated_words = []\n",
    "\n",
    "# Loop through generated sentences and make list of generated words\n",
    "for generated_sentence in generated_sentences:\n",
    "    generated_words += generated_sentence.split()\n",
    "\n",
    "# Get unique generated words with set()\n",
    "generated_words_unique = set(sorted(generated_words))\n",
    "len(generated_words_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all of artist's words from his/her lyrics for comparison\n",
    "all_artist_words = text.replace(\"'\", '').split(' ')\n",
    "\n",
    "# Get unique artist words with set()\n",
    "artist_words_unique = set(sorted(all_artist_words))\n",
    "len(artist_words_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratio of generated words that are words the artist actually uses\n",
    "len(generated_words_unique.intersection(artist_words_unique)) / len(generated_words_unique)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN5DlgLLWN4fLcBv+vdUHbA",
   "collapsed_sections": [],
   "name": "lyric_generator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
